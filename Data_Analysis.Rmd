---
title: "AIR QUALITY INDEX-INDIA DATA ANALYSIS"
subtitle: "Statistical Methods II Spring Project"
author: "RishiDarkDevil"
date: "6/27/2021"
output: 
  html_document:
    keep_md: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(lubridate)
library(modelr)
library(psych)
library(car)
library(GGally)
library(ggpubr)
library(ggrepel)
library(purrr)
library(knitr)
library(kableExtra)
library(stringr)
library(viridis)
library(formattable)
library(skimr)
library(moderndive)
library(infer)
#library(fitdistrplus)
library(pander)
library(stargazer)
library(forcats)
library(broom)
options(dplyr.summarise.inform = FALSE)
```

```{r raw_data, cache=TRUE, include=FALSE}
# Importing my data sets
air_data_world <- read_csv("E:\\MY COLLEGE\\ISI KOLKATA\\1ST YEAR\\PROJECTS\\2ND SEM\\STATISTICAL METHODS II\\Air Quality Index\\all_air_data.csv", comment = '#')
air_data_world
station_list <- readxl::read_excel("E:\\MY COLLEGE\\ISI KOLKATA\\1ST YEAR\\PROJECTS\\2ND SEM\\STATISTICAL METHODS II\\Air Quality Index\\Station_List.xlsx", skip = 1)
```

```{r processed_data, cache=TRUE, dependson="raw_data", include=FALSE}
# Separating out the date column for easier analysis
air_data_world <- air_data_world %>%
  mutate(Year = year(Date), Month = month(Date), Day = day(Date)) %>%
  select(Year, Month, Day, Country, City, Specie, count, min, max, median, variance)

# Filtering Data relevant to INDIA
air_data_india <- air_data_world %>%
  filter(Country == "IN")
air_data_india <- air_data_india %>%
  select(Year:Day, City:variance)
air_data_india
air_data_india_withDate <- air_data_world %>%
  filter(Country =="IN")

# Changing some basic flaws in data
correct <- function(x) return(ifelse(x == "wind speed", "wind-speed", x))
air_data_india$Specie <- correct(air_data_india$Specie)
correct <- function(x) return(ifelse(x == "wind gust", "wind-gust", x))
air_data_india$Specie <- correct(air_data_india$Specie)
air_data_india <- air_data_india %>%
  filter(Specie != "wd")
correct <- function(x) return(ifelse(x == "New Delhi", "Delhi", x))
air_data_india$City <- correct(air_data_india$City)

# Arranging the Data according to Year
air_data_india <- air_data_india %>%
  arrange(Year, Month, Day)
air_data_india

# Trying to separate the column Specie for easier analysis -- widening the data
spec1 <- air_data_india %>%
  build_wider_spec(names_from = Specie, values_from = c(count, min, max, median, variance, Year, Month, Day, City))
spec1
# Separate based on Specie
air_data_india_Specie <- air_data_india %>%
  group_by(Specie) %>%
  mutate(row = row_number()) %>%
  pivot_wider_spec(spec1) %>%
  select(-row) %>%
  select(contains("Year"), contains("Month"), contains("Day"), contains("City"), everything())
air_data_india_Specie

# Separate based on City
spec2 <- air_data_india %>%
  build_wider_spec(names_from = City, values_from = c(Specie, count, min, max, median, variance, Year, Month, Day, City))
spec2

air_data_india_City <- air_data_india %>%
  group_by(City) %>%
  mutate(row = row_number()) %>%
  pivot_wider_spec(spec2) %>%
  select(-row) %>%
  select(contains("Year"), contains("Month"), contains("Day"), contains("City"), everything())
air_data_india_City

# Filtering out the pollutants only
air_data_india_pollutants <- air_data_india %>%
  filter(Specie %in% c('pm25', 'pm10', 'o3', 'so2', 'no2', 'co'))

# Filtering out the non-pollutants
air_data_india_nonpollutants <- air_data_india %>%
  filter(!(Specie %in% c('pm25', 'pm10', 'o3', 'so2', 'no2', 'co')))

# What Columns are present in my Data?
colnames(air_data_india)
unique(air_data_india$City)
unique(air_data_india$Specie)

# Making List of Stations.
colnames(station_list) <- c("Sl.No.State", "State", "Sl.No.City", "City", "Sl.No.Station", "Station")
station_list <- station_list %>%
  select(State, City, Station) %>%
  fill(State) %>%
  fill(City) %>%
  fill(Station)
station_list

station_list <- station_list %>%
  filter(City %in% unique(air_data_india$City)) %>%
  group_by(State, City) %>%
  summarise("Number of Stations" = n())
```

# INTRODUCTION

In this Data Analysis Project, I am going to work with **Air Quality Index Data of India**. I will be using several Statistical Tools to Analyze the Data which includes Exploratory Data Analysis, Techniques and methodologies used for Inference and will be Modelling the Data to summarize any pattern or general trend.

I will also try to find out if there was any significant drop in the levels pollutant gases in the Atmosphere due to imposing lockdowns in the year 2020 and 2021, when several industries, factories, transportation facilities were suspended to work. I will be comparing the data for 2020 and 2021 with the previous years.

### UNDERSTANDING THE DATASET

Let's take a look at the Data

```{r}
kable(head(air_data_india), caption = "First few rows of the Air Quality Index Data") %>%
  kable_styling(position = "center")
kable(tail(air_data_india), caption = "Last few rows of the Air Quality Index Data") %>%
  kable_styling(position = "center")
```

-   This Data set contains `r nrow(air_data_india)` rows and `r ncol(air_data_india)` columns.

-   The Year ranges from 2014 to 2021 (till June), with observations recorded on each of the 30 /31 days of the month for 12 months.

-   The Data is generated from the `r length(unique(air_data_india$City))` City Stations for Real-Time Air-Quality Index Monitoring across the Country. The Cities include:

```{r}
kable(station_list, caption = "City Stations") %>%
  kable_styling(position = "center")
```

-   The parameters which we measure at the different Stations are given under the Specie Column and it includes -

```{r Specie_description}
Specie_description <- tibble(
  Parameters = unique(air_data_india$Specie),
  Description = c(
    "Particle pollution/particulate matter(particles less than or equal to 2.5 micrometers in diameter)",
    "Particle pollution/particulate matter(particles less than or equal to 10 micrometers in diameter)",
    "Ground-level ozone",
    "Sulfur dioxide",
    "Nitrogen dioxide",
    "Carbon Monoxide",
    "Temperature",
    "Air Pressure",
    "Wind Gust/Force",
    "Relative Humidity",
    "Wind Speed",
    "Dew Point",
    "Precipitation"
  ),
  Units = c("AQI","AQI","AQI","AQI","AQI","AQI","Degree Celcius",NA,NA,NA,NA,NA,NA)
)
kable(Specie_description, caption = "Specie Description") %>%
  kable_styling(position = "center")
```

The Air Quality Index (AQI) is an index for reporting air quality on a daily basis. It measures air pollution affects one's health within a short time period. The purpose of the AQI is to help people know how the local air quality impacts their health. The measurements in AQI are particularly helpful for our Data Analysis as it helps us compare the values at different stations and time points.

-   It also helps in identifying faulty standards and inadequate monitoring programmes.

-   AQI helps in analysing the change in air quality (improvement or degradation).

-   Comparing air quality conditions at different locations/cities.

```{r AQI_Info}
AQI_Info <- tibble(
  "AQI Values" = c(
    "0-50",
    "51-100",
    "101-150",
    "151-200",
    "201-300",
    "301-500"
  ),
  "Level of Health Concern" = c(
    "Good",
    "Moderate",
    "Unhealthy for sensitive group",
    "Unhealthy",
    "Very Unhealthy",
    "Hazardous"
  )
)
kable(AQI_Info, caption = "Significance of the AQI Values") %>%
  kable_styling(position = "center")
```

In further Analysis we will call pm25, pm10, o3, so2, no2 and co2 as pollutants and the remaining parameters as non-pollutants.

-   For Each parameters in Specie we measure it's minimum value, median value, maximum value and variance . The count variable is the number of times the measurement was taken for each of the parameters.

### TOP CITY STATIONS

Here we try to analyze which City Stations

-   Records More Observations compared to others, which will give us an idea of those centres being more frequently continuously recorded, which can be due to higher AQI Levels in the pollutants.

```{r obsv_per_station, fig.asp=0.618, fig.width=12}
obsv_per_station <- air_data_india %>%
  group_by(Year, City) %>%
  count() %>%
  arrange(Year, desc(n)) %>%
  spread(key = Year, value = n) %>%
  arrange(desc(`2019`, `2020`, `2021`))

air_data_india %>%
  group_by(Year, City) %>%
  count() %>%
  filter(Year %in% c("2021", "2020", "2019", "2018")) %>%
  ggplot(aes(City, n, fill = City)) +
  geom_bar(stat = "identity") +
  facet_wrap(~Year) +
  coord_flip() +
  labs(
    x = "Number of Observations Recorded"
  ) +
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 3,
      override.aes = list(size = 3)
    )
  ) +
  scale_color_viridis(discrete = TRUE)
```

It is clearly visible that Delhi is definitely the most monitored centre, which is due to the presence the highest number of Real-Time Air Monitoring Stations in Delhi and more frequent montioring which is due to high AQI Levels which we will see in further analysis. The other centres have more or less the same number of observations.

-   Now Let's take a look at the Average Median AQI Levels of the Pollutants every year Station-wise. The Top 11 Stations will be considered in the further analysis where ever we need to do a Station-wise breakdown of Data or Analysis.

```{r avg_median_per_year_per_station, fig.asp=0.618, fig.width=12}
avg_median_per_year_per_station <- air_data_india_pollutants %>%
  group_by(Year, City) %>%
  summarise(Median = mean(median)) %>%
  arrange(desc(Year, Median)) %>%
  spread(key = Year, value = Median) %>%
  arrange(desc(`2021`, `2020`, `2019`, `2018`))

air_data_india_pollutants %>%
  group_by(Year, City) %>%
  summarise(Median = mean(median)) %>%
  arrange(desc(Year, Median)) %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  ggplot(aes(City, Median, fill = City)) +
  geom_bar(stat = "identity") +
  facet_wrap(~Year) +
  coord_flip() +
  labs(
    y = "Average Median AQI Levels of Pollutants"
  ) +
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 3,
      override.aes = list(size = 3)
    )
  ) +
  scale_color_viridis(discrete = TRUE)
```

# VISUAL OVERVIEW

-   Here we will look at several visualization to get an approximate idea about the spread, patterns, trends and key facts to notice about the Data, which will greatly impact our further Analysis and will prove helpful in finding out the parts of the Data which needs to be observed and tested carefully to provide valuable insight.

```{r Yearly_Station_Bar, fig.asp=0.618, fig.width=12}
air_data_india_pollutants %>%
  group_by(Year, City) %>%
  summarise(Median = mean(median)) %>%
  arrange(desc(Year, Median)) %>%
  filter(Year != 2014) %>%
  ggplot(aes(Year, Median)) +
  geom_bar(aes(fill = City), position = "dodge", stat = "identity") +
  labs(
    y = "Average Median AQI Levels"
  ) +
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 2,
      override.aes = list(size = 3)
    )
  ) +
  scale_fill_viridis(discrete = TRUE)
```

Here, from above bar plot, we see that the year 2020 was the one with the least levels of Pollutants compared to all the other years. 2021 has seen a hike in the AQI levels, which maybe due to opening of the factories, industries and also starting of Transportation facilities in many States. Though we cannot totally claim that, because we don't have data pertaining to entire of 2021.

```{r City_AQI_Box, fig.asp=0.618, fig.width=12}
air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)), City %in% avg_median_per_year_per_station$City[1:11]) %>%
  ggplot(aes(City, median, fill =cut_width(Year, 1))) +
  geom_boxplot(outlier.shape = NA) + 
  coord_cartesian(ylim = c(0, 350)) +
  labs(y = "Average Median AQI Levels", fill = "Year") +
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  )
```

Taking look at the Top 11 Stations we can also see a drop in the AQI levels in the year 2020.

-   Here is an interesting relationship between month and average AQI levels per day of that Month, where we see that the AQI levels in each Measure drop almost linearly till July each year and then it starts rising. We will later explore this relationship in the Modelling Part of this Analysis.

```{r AQI_Yearly_Viz, fig.asp=0.618, fig.width=12}
Monthly_Pollutant <- air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  group_by(Year, Month) %>%
  summarise(Avg_Min = mean(min), Avg_Median = mean(median), Avg_Max = mean(max))

Monthly_Pollutant_1 <- Monthly_Pollutant %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI")

Monthly_Pollutant_1 %>%
  ggplot(aes(Month, AQI)) +
  geom_point(aes(color = Year, shape = Measure), size = 6, alpha = 0.66) +
  labs(
    y = "Average AQI Levels"
  ) +
  scale_color_viridis(option = "H")
```

-   The Past 4 years Station-wise we can see the same pattern with Delhi being at the top of each month. This answers the question of why Delhi has so many more Observations recorded per year as compared to the other Stations. It's the concerning and high levels of AQI levels.

-   Now we see even more revealing pattern when we plot our Top 11 Station's Measure of AQI Levels in the last 4 years. The Maximum AQI Levels measured each day per month increases and then decreases till July where previously in the above plot which merged all the Stations didn't showed this much. This kind of behavior is ore pronounced in Delhi.

```{r Station_Monthly_Viz, fig.asp=0.618, fig.width=12}
Monthly_Pollutant_City <- air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)) & City %in% avg_median_per_year_per_station$City[1:11]) %>%
  group_by(Year, Month, City) %>%
  summarise(Avg_Min = mean(min), Avg_Median = mean(median), Avg_Max = mean(max))

Monthly_Pollutant_City_1 <- Monthly_Pollutant_City %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI")

Monthly_Pollutant_City_1 %>%
  ggplot(aes(Month, AQI)) +
  geom_point(aes(color = City, alpha = 0.7, shape = Measure), size = 4) +
  facet_wrap(~Year) +
  scale_color_viridis(discrete = TRUE, option = "H")
```

-   Let's turn to the Pollutant-wise breakdown of the AQI Levels, which may help us find out weather it was actually the Lockdowns which may have caused a dip in the AQI levels during the year 2020.

```{r Specie_Yearly_Viz, fig.asp=0.618, fig.width=12}
Yearly_Specie <- air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  group_by(Year, Specie) %>%
  summarise(Avg_Min = mean(min), Avg_Median = mean(median), Avg_Max = mean(max))

Yearly_Specie_1 <- Yearly_Specie %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI") %>%
  spread(key = Specie, value = AQI)

air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  gather(min, median, max, key = "Measure", value = "AQI") %>%
  ggplot(aes(Specie, AQI, fill = cut_width(Year, 1))) +
  geom_boxplot(outlier.shape = NA) +
  coord_cartesian(ylim = c(0,300)) +
  labs(fill = "Year")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  )
```

Here we can clearly see that each Pollutant has decreased in the Year 2020 compared to all the other Years. But more interesting is the fact that particulate matter of both sizes have shown a big drop. Particulate Matters are mostly contributed by Vehicles, Transportation facilities and some Industries like Cement, etc. Since, there was lockdown we see it might have caused such a dip. Other Pollutants have also seen drop in the Year 2020. Further in the Analysis we will do Statistical Tests to find out if these drops were significant or not.

```{r Monthly_Pollutant_Viz_and_Daily_Data_wrangling_included, fig.asp=0.618, fig.width=12}
Monthly_Specie <- air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  group_by(Year, Month, Specie) %>%
  summarise(Avg_Min = mean(min), Avg_Median = mean(median), Avg_Max = mean(max))
 

Monthly_Specie_1 <- Monthly_Specie %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI") %>%
  spread(key = Specie, value = AQI)


Monthly_Specie_2 <- Monthly_Specie_1 %>%
  gather(co:so2, key = "Pollutants", value = "AQI")

air_data_india_All_Specie_Daily <- air_data_india %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  group_by(Year, Month, Day,  Specie) %>%
  summarise(Avg_Min = mean(min, na.rm = TRUE), Avg_Median = mean(median, na.rm = TRUE), Avg_Max = mean(max, na.rm = TRUE))

air_data_india_All_Specie_Daily_1 <- air_data_india_All_Specie_Daily %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI")

air_data_india_All_Specie_Daily_2 <- air_data_india_All_Specie_Daily_1 %>%
  spread(key = Specie, value = AQI)

Monthly_Specie_2 %>%
  ggplot(aes(Month, AQI)) +
  geom_point(aes(color = Pollutants, shape = Measure), alpha = 0.66, size = 5) +
  labs(
    y = "Average AQI Levels"
  ) +
  facet_wrap(~Year) +
  scale_color_viridis(discrete = TRUE, option = "B")
```

### DISTRIBUTIONS

Distributions are key in deciding any changes been made to the system generating the data. They help us distinguish between two different groups. They help us look at the spread of the data and helps us take important decisions regarding what inferential techniques we can use and what sort of assumptions are valid. They are also fundamental part before doing any kind of Testing or Model Building.

-   Let's take a look at the Yearly Distribution of the Median AQI Levels

```{r Yearly_Pollutant_Hist, fig.asp=0.618, fig.width=12}
air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)) & !(Specie %in% c('pm25', 'pm10'))) %>%
  ggplot(aes(median, ..density.., fill = cut_width(Year,1), group = Year)) +
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(xlim = c(0, 50)) +
  facet_wrap(~Year) +
  labs(fill = "Year", x = "Median AQI Levels[Excluding pm10 & pm25]", y = "Density")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  scale_fill_viridis(discrete = TRUE)
```

They look quite familiar to Gamma Distribution. Later in the Inference Part we will try to find out the parameters and will do several Tests to verify this. We will also perform tests for whether the Year 2020 saw a dip in these AQI Levels.

We see more or less same distribution for Maximum AQI Levels and Minimum AQI Levels.

```{r Yearly_Pollutant_Hist_1, fig.asp=0.618, fig.width=12, out.width='.49\\linewidth',fig.show='hold',fig.align='center'}
air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)) & !(Specie %in% c('pm25', 'pm10'))) %>%
  ggplot(aes(max, ..density.., fill = cut_width(Year,1), group = Year)) +
  geom_histogram(binwidth = 1) +
  coord_cartesian(xlim = c(0, 200)) +
  facet_wrap(~Year) +
  labs(fill = "Year", x = "Max AQI Levels[Excluding pm10 & pm25]", y = "Density")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  scale_fill_viridis(discrete = TRUE)

air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)) & !(Specie %in% c('pm25', 'pm10'))) %>%
  ggplot(aes(min, ..density.., fill = cut_width(Year,1), group = Year)) +
  geom_histogram(binwidth = 0.1) +
  coord_cartesian(xlim = c(0, 10)) +
  facet_wrap(~Year) +
  labs(fill = "Year", x = "Min AQI Levels[Excluding pm10 & pm25]", y = "Density")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  scale_fill_viridis(discrete = TRUE)
```

-   A Pollutant-wise (Excluding pm10 and pm25) breakdown of the Median AQI Levels also reveal similar Gamma looking Distributions but with different parameters.

```{r Yearly_Indiv_Pollutant_Hist, fig.asp=0.618, fig.width=12}
air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)) & !(Specie %in% c('pm25', 'pm10'))) %>%
  ggplot(aes(median, ..density.., fill = Specie, group = Specie)) +
  geom_histogram(binwidth = 0.5) +
  coord_cartesian(xlim = c(0, 30)) +
  facet_wrap(~Year + Specie, labeller = label_wrap_gen(multi_line=FALSE)) +
  labs(fill = "Year", x = "Median AQI Levels[Excluding pm10 & pm25]", y = "Density")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  scale_fill_viridis(discrete = TRUE)
```

-   Now in all these above plots we have skipped pm10 and pm25 since they have much higher values of AQI compared to these gases. So, we won't be able to fit them in the above plots. Added with that pm25 doesn't seem to follow some known distribution. We will later see if any transformation or change can help us model that.

```{r Yearly_Indiv_Pollutant_Hist_2, fig.asp=0.618, fig.width=12}
air_data_india_pollutants %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017)) & (Specie %in% c('pm25', 'pm10'))) %>%
  ggplot(aes(median, ..density.., fill = cut_width(Year,1), group = Year)) +
  geom_histogram(binwidth = 5) +
  coord_cartesian(xlim = c(0, 200)) +
  facet_wrap(~Year + Specie, labeller = label_wrap_gen(multi_line=FALSE)) +
  labs(fill = "Year", x = "Median AQI Levels", y = "Density")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  scale_fill_viridis(discrete = TRUE)
```

### RELATIONSHIPS - PATTERNS & TRENDS

Here we are going to explore the visual relationships between all the pollutants with all the other pollutants and not only that, it is important to realize that the non-pollutants also play a crucial role in deciding the level of pollutants measured. We will see more of it below in this section as well as a lot of it in the section where we build our Models. These relationships are best exposed with Scatter plots. Here we will take a look at these.

-   Here we look at the Scatter Plot matrix of the Pollutants where we have summarized the data in Yearly & Monthly basis so as to make the plots less overwhelming and more interpretable. We see strong correlation between all these marginals plots. Which can be attributed due to the conversions of one gas to the other that takes place naturally in the atmosphere. But we must also be careful that it may happen that these individual pollutants are related due to some other underlying common feature, which we will explore further in the Model Building section.

```{r Monthly_Specie_Scatterplot_Matrix, fig.asp=0.618, fig.width=12, message=FALSE, warning=FALSE}
# Exploring the relationships between All Species with each other Monthly
air_data_india_All_Specie_Monthly <- air_data_india %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  group_by(Year, Month, Specie) %>%
  summarise(Avg_Min = mean(min, na.rm = TRUE), Avg_Median = mean(median, na.rm = TRUE), Avg_Max = mean(max, na.rm = TRUE))

air_data_india_All_Specie_Monthly_1 <- air_data_india_All_Specie_Monthly %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI")

air_data_india_All_Specie_Monthly_2 <- air_data_india_All_Specie_Monthly_1 %>%
  spread(key = Specie, value = AQI)

# Actually here all the parameters with all the others except Year and Month are really highly correlated. So let's take a look at them 
air_data_india_All_Specie_Monthly_2 %>%
  ggpairs(columns = c("co", "no2", "o3", "so2", "pm10", "pm25"), aes(color = cut_width(Year, 1), shape = cut_width(Year, 1)), progress = FALSE) +
  scale_color_viridis(discrete = TRUE)

air_data_india_All_Specie_Monthly_2 %>%
  filter(Year != 2018) %>% # There is a lot of Missing values in this year
  ggpairs(columns = c("dew", "humidity", "pressure", "temperature", "wind-gust", "wind-speed"), aes(color = cut_width(Year, 1), shape = cut_width(Year, 1)), progress = FALSE) +
  scale_color_viridis(discrete = TRUE)
```

Here we see that the non-pollutants also have strong correlations among themselves, which can be attributed for the fact that temperature, pressure, humidity, wind-speed, etc. are physically strongly related.

-   Let's take a look at the dependence of the Pollutants on Non-Pollutants

```{r Monthly_Pol_non_Pol_Scatterplot_Matrix, fig.asp=0.618, fig.width=12}
air_data_india_Pollutants_nonpollutants_monthly <- air_data_india_All_Specie_Monthly_1 %>%
  filter(Year != 2018) %>% # There is a lot of Missing values in this year
  spread(key = Specie, value = AQI) %>%
  select(-precipitation) %>%
  gather(dew, humidity, pressure, temperature, `wind-gust`, `wind-speed`, key = "non_pollutants", value = Levels) %>%
  gather(co, so2, no2, o3, pm10, pm25, key = "pollutants", value = "AQI")

air_data_india_Pollutants_nonpollutants_monthly %>%
  ggplot(aes(AQI, Levels, color = cut_width(Year, 1))) +
  geom_point() +
  scale_color_viridis(discrete = TRUE) +
  facet_wrap(~pollutants + non_pollutants, scales = "free", labeller = label_wrap_gen(multi_line=FALSE)) +
  labs(color = "Year") +
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  coord_flip() +
  scale_fill_viridis(discrete = TRUE)
```

There is a significant relationship between each of the non-pollutants on the AQI levels of the pollutants, which may be due to the fact that wind speeds, temperature, pressure, humidity, etc. changes the concentration of the pollutants in the Air. There are other physical processes in nature that also strongly intertwine them. We will see more of it in the later sections.

-   One really important thing to keep in mind is the measured values(Levels) of non-pollutants change with seasons, and months of the Year. So this effect should be kept in mind.

```{r Monthly_nonpol_viz, fig.asp=0.618, fig.width=12}
air_data_india_Pollutants_nonpollutants_monthly %>%
  ggplot(aes(Month, Levels, fill = cut_width(Year, 1))) +
  geom_hex() +
  facet_wrap(~non_pollutants, scales = "free") +
  labs(fill = "Year", y = "Levels")+
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  ) +
  scale_fill_viridis(discrete = TRUE)
```

-   There is also one more thing which can prove to be really helpful in understanding the relationship between the pollutants that is the variance of these parameters measured each day at the stations at real-time. Where we can see how these parameters variances are related. I haven't included the scatterplot matrix of the non-pollutants and of the pollutants and non-pollutants, as they visually don't convey much. But we will surely work with them in the later section.

```{r Monthly_Pol_non_Pol_Scatterplot_Matrix_Var, fig.asp=0.618, fig.width=12, message=FALSE, warning=FALSE}
air_data_india_All_Specie_Monthly_var <- air_data_india %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017))) %>%
  group_by(Year, Month, Specie) %>%
  summarise(Avg_Variance = mean(variance, na.rm = TRUE))

air_data_india_All_Specie_Monthly_var_1 <- air_data_india_All_Specie_Monthly_var %>%
  spread(key = Specie, value = Avg_Variance)

air_data_india_All_Specie_Monthly_var_1 %>%
  ggpairs(columns = c("co", "no2", "o3", "so2", "pm10", "pm25"), aes(color = cut_width(Year, 1), shape = cut_width(Year, 1)), progress = FALSE) +
  scale_color_viridis(discrete = TRUE)

air_data_india_Pollutants_nonpollutants_monthly_var_1 <- air_data_india_All_Specie_Monthly_var_1 %>%
  filter(Year != 2018) %>% # There is a lot of Missing values in this year
  select(-precipitation) %>%
  gather(dew, humidity, pressure, temperature, `wind-gust`, `wind-speed`, key = "non_pollutants", value = "Levels_variance") %>%
  gather(co, so2, no2, o3, pm10, pm25, key = "pollutants", value = "AQI_variance")
```

So, with this visual picture of the Data in mind. We wrap the Visual Overview and most part of the EDA here. In the next section we will draw inferences from the data using several Inferential Statistical Technique.

# STATISTICAL INFERENCE

So, far what we have seen is a qualitative analysis, where we have looked at several visualizations which gave us a clear idea of what we see in the data. Now, it's time to ask some important questions regarding the data and trying to find quantitative answers to them. This will help us solidify our claims and believes which have in our mind after looking at the EDA. We will also strengthen our grip on the data by fitting several probability Models to the Histograms and Distributions we have seen in the previous section.

-   We will conduct all Tests, wherever needed, at a *0.01 level of significance*. Similarly, the Confidence Intervals wherever used will be *99% confidence intervals*.

### HYPOTHESIS TESTING

-   Let's get back to the first question with which we started the the Visual Overview of our data. It is clear that Delhi's number of observations recorder per year is much higher than the other. But the number of observations of other Cities look more or less same. Let's Test our Hypothesis of whether the proportion of the total observations recorded in a year are same for all the cities (Top 11) except Delhi.

```{r observation_prop_viz_and_chisq_test_for_prop, fig.asp=0.618, fig.width=12}
p1 <- obsv_per_station %>%
  gather(`2021`, `2020`, `2019`, key = "Year", value = Observations) %>%
  select(City, Year, Observations) %>%
  filter(City %in% avg_median_per_year_per_station$City[1:11]) %>%
  ggplot(aes(City, Observations, fill = City)) +
  geom_bar(stat = "identity") +
  facet_wrap(~Year) +
  coord_flip() +
  labs(
    x = "Number of Observations Recorded"
  ) +
  theme(legend.position = "None") +
  scale_color_viridis(discrete = TRUE)

print_chisq_prop <- function(test){
  table <- tibble(
    `Test Statistic` = test$statistic,
    df = test$parameter,
    `p-value` = test$p.value,
  )
  return(list("test_table" = table))
}

test0 <- obsv_per_station %>%
  ungroup() %>%
  filter(City != "Delhi" & City %in% avg_median_per_year_per_station$City[1:11]) %>% # Since it is clearly different
  select(`2019`) %>%
  chisq.test()
test0 <- print_chisq_prop(test0)
table0 <- ggtexttable(test0$test_table, theme = ttheme("mBlue")) %>%
  tab_add_footnote(text = "Chi-sq Test for Equality of Proportion 2019", size = 10, face = "italic")

test1 <- obsv_per_station %>%
  ungroup() %>%
  filter(City != "Delhi" & City %in% avg_median_per_year_per_station$City[1:11]) %>% # Since it is clearly different
  select(`2020`) %>%
  chisq.test()
test1 <- print_chisq_prop(test1)
table1 <- ggtexttable(test1$test_table, theme = ttheme("mBlue")) %>%
  tab_add_footnote(text = "Chi-sq Test for Equality of Proportion 2020", size = 10, face = "italic")

test2 <- obsv_per_station %>%
  ungroup() %>%
  filter(City != "Delhi" & City %in% avg_median_per_year_per_station$City[1:11]) %>% # Since it is clearly different
  select(`2021`) %>%
  chisq.test()
test2 <- print_chisq_prop(test2)
table2 <- ggtexttable(test2$test_table, theme = ttheme("mBlue")) %>%
  tab_add_footnote(text = "Chi-sq Test for Equality of Proportion 2021", size = 10, face = "italic")

p2 <- ggarrange(table0, table1, table2, ncol = 3)
ggarrange(p1, p2, nrow = 2, heights = c(6, 1))
```

We performed the **chi-square test for equality of proportion** on Year 2019, 2020 and 2021 respectively and clearly we fail to reject the null Hypothesis for the recent 2 years. Hence, all other City Stations except Delhi are equally monitored in the last 2 years.

-   Now, It is a natural question to ask - whether the AQI Levels of the pollutants similar across all the City Stations?

To answer this Question we can compare the mean AQI Levels of the City Stations. So, we can perform an **One-Factor Analysis of Variance** to test our Null Hypothesis of the mean AQI Levels of all the City Stations are equal.

```{r average_pollutant_one_factor_anova, fig.asp=0.618, fig.width=12, warning=FALSE}

air_data_all_specie_yearly_city_included <- air_data_india %>%
  filter(!(Year %in% c(2014, 2015, 2016, 2017, 2018))) %>%
  group_by(Year, City, Specie) %>%
  summarise(Avg_Min = mean(min, na.rm = TRUE), Avg_Median = mean(median, na.rm = TRUE), Avg_Max = mean(max, na.rm = TRUE)) %>%
  gather(Avg_Min, Avg_Median, Avg_Max, key = "Measure", value = "AQI")

air_data_pollutants_yearly_city_included <- air_data_all_specie_yearly_city_included %>%
  filter(Specie %in% c("co", "no2", "o3", "so2", "pm10", "pm25"))

air_data_nonpollutants_yearly_city_included <- air_data_all_specie_yearly_city_included %>%
  filter(!(Specie %in% c("co", "no2", "o3", "so2", "pm10", "pm25")))

plt1 <- air_data_pollutants_yearly_city_included %>%
  filter(Year == 2019 & City %in% avg_median_per_year_per_station$City[1:11]) %>%
  ggplot(aes(AQI, City, fill = City)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  coord_cartesian(xlim = c(0, 200)) +
  scale_y_discrete(labels = NULL) +
  geom_vline(
    xintercept = mean(filter(air_data_pollutants_yearly_city_included, Year == 2019 & City %in% avg_median_per_year_per_station$City[1:11])$AQI), size = 1
  ) +
  ggtitle("2019") +
  theme(legend.position = "None") +
  scale_fill_viridis(discrete = TRUE)

test3 <- aov(AQI ~ City, filter(air_data_pollutants_yearly_city_included, City %in% avg_median_per_year_per_station$City[1:11] & Year == 2019))
test3 <- summary(test3)
test3 <- unclass(test3)
test3 <- cbind("Source" = rownames(test3[[1]]), test3[[1]])
test3 <- as_tibble(test3)
table1 <- ggtexttable(test3, theme = ttheme("mBlue")) %>%
  tab_add_footnote(text = "One-Factor ANOVA for 2019", size = 10, face = "italic")


plt2 <- air_data_pollutants_yearly_city_included %>%
  filter(Year == 2020 & City %in% avg_median_per_year_per_station$City[1:11]) %>%
  ggplot(aes(AQI, City, fill = City)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  coord_cartesian(xlim = c(0, 200)) +
  scale_y_discrete(labels = NULL) +
  geom_vline(
    xintercept = mean(filter(air_data_pollutants_yearly_city_included, Year == 2020 & City %in% avg_median_per_year_per_station$City[1:11])$AQI), size = 1
  ) +
  ggtitle("2020") +
  theme(legend.position = "None") +
  scale_fill_viridis(discrete = TRUE)

test4 <- aov(AQI ~ City, filter(air_data_pollutants_yearly_city_included, City %in% avg_median_per_year_per_station$City[1:11] & Year == 2020))
test4 <- summary(test4)
test4 <- unclass(test4)
test4 <- cbind("Source" = rownames(test4[[1]]), test4[[1]])
test4 <- as_tibble(test4)
table2 <- ggtexttable(test4, theme = ttheme("mBlue"))%>%
  tab_add_footnote(text = "One-Factor ANOVA for 2020", size = 10, face = "italic")

plt3 <- air_data_pollutants_yearly_city_included %>%
  filter(Year == 2021 & City %in% avg_median_per_year_per_station$City[1:11]) %>%
  ggplot(aes(AQI, City, fill = City)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  coord_cartesian(xlim = c(0, 200)) +
  scale_y_discrete(labels = NULL) +
  geom_vline(
    xintercept = mean(filter(air_data_pollutants_yearly_city_included, Year == 2021 & City %in% avg_median_per_year_per_station$City[1:11])$AQI), size = 1
  ) +
  ggtitle("2021") +
  theme(legend.position = "bottom") +
  guides(
    fill = guide_legend(
      nrow = 2
    )
  ) +
  scale_fill_viridis(discrete = TRUE)

test5 <- aov(AQI ~ City, filter(air_data_pollutants_yearly_city_included, City %in% avg_median_per_year_per_station$City[1:11] & Year == 2021))
test5 <- summary(test5)
test5 <- unclass(test5)
test5 <- cbind("Source" = rownames(test5[[1]]), test5[[1]])
test5 <- as_tibble(test5)
table3 <- ggtexttable(test5, theme = ttheme("mBlue")) %>%
  tab_add_footnote(text = "One-Factor ANOVA for 2021", size = 10, face = "italic")

table <- ggarrange(table1, table2, table3, nrow = 3)

ggarrange(plt1, plt2, plt3, table)
```

It is clear from the p-values that indeed the average AQI Levels of Pollutants in all the Top City Stations same in the past 3 Years.

-   Now the Question that rises is whether the Mean AQI Level of Pollutants in 2020 Less than that of 2019? Along with it we will also find out whether the Mean AQI Level of Pollutants in 2021 More than that of 2020 (Considering the Data of the First 6 months of 2020 and 2021)?

It is natural to think so, as India saw several Lockdowns at different places as well as a Nation-wide Lockdown in 2020, during which Major Factories and transportation facilities were closed, which usually are the top contributors of these Pollutants. Whereas in the Later months of 2020 and in 2021 Lockdown was mostly lifted and we may suspect that the Mean AQI Levels of Pollutants have increased.

So, to Test our Hypothesis of whether the Mean AQI Level of 2020 less than that of 2019 against the Alternative that the Mean AQI Level has Dropped in 2020, we will perform a **two sample t-test for equality of mean**. Here after looking at the boxplots, the variances for each year looks more or less the same, and I took variances of both the samples to be same.

```{r average_pollutant_yearly_t_test, fig.asp=0.618, fig.width=12, warning=FALSE, cache=TRUE}
air_data_india_Pollutants_Daily <- air_data_india_All_Specie_Daily_1 %>%
  group_by(Year, Month, Day) %>%
  filter(Specie %in% c("co", "no2", "o3", "so2", "pm10", "pm25")) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

plt1 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020)) %>%
  mutate(Year = as.character(Year)) %>%
  ggplot(aes(Year, Mean_AQI, fill = Year)) +
  geom_boxplot() +
  stat_summary(fun = "mean") +
  coord_cartesian(ylim = c(20, 100)) +
  labs(y = "Mean AQI", x = NULL) +
  geom_hline(
    yintercept = mean(filter(air_data_india_Pollutants_Daily, Year %in% c(2019, 2020))$Mean_AQI, na.rm = TRUE), size = 1
  )+
  theme(legend.position = "None")

null_distribution1_t <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  hypothesise("independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("2020", "2019"))

obs_diff_means1 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  calculate(stat = "t", order = c("2020", "2019"))

sim_test_statistic1 <- visualise(null_distribution1_t, method = "both") +
  shade_p_value(obs_stat = obs_diff_means1, direction = "left")

test1 <- t.test(filter(air_data_india_Pollutants_Daily, Year == 2020)$Mean_AQI, filter(air_data_india_Pollutants_Daily, Year == 2019)$Mean_AQI,
                alternative = "less", var.equal = TRUE, conf.level = 0.99)

table1 <- ggtexttable(map_df(list(test1), tidy), theme = ttheme("mOrange")) %>%
  tab_add_footnote(text = "two-sample t-test for 2019 & 2020", size = 10, face = "italic")

plt2 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2020, 2021) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  ggplot(aes(Year, Mean_AQI, fill = Year)) +
  geom_boxplot() +
  stat_summary(fun = "mean") +
  coord_cartesian(ylim = c(20, 100)) +
  labs(y = "Mean AQI", x = NULL) +
  geom_hline(
    yintercept = mean(filter(air_data_india_Pollutants_Daily, Year %in% c(2020, 2021) & Month %in% c(1,2,3,4,5,6) )$Mean_AQI, na.rm = TRUE), size = 1
  )+
  theme(legend.position = "None")

null_distribution2_t <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2021, 2020) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  hypothesise("independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("2021", "2020"))

obs_diff_means2 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2021, 2020) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  calculate(stat = "t", order = c("2021", "2020"))

sim_test_statistic2 <- visualise(null_distribution2_t, method = "both") +
  shade_p_value(obs_stat = obs_diff_means2, direction = "right")

test2 <- t.test(filter(air_data_india_Pollutants_Daily, Year == 2021 & Month %in% c(1,2,3,4,5,6))$Mean_AQI, filter(air_data_india_Pollutants_Daily, Year == 2020 & Month %in% c(1,2,3,4,5,6))$Mean_AQI,
                alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table2 <- ggtexttable(map_df(list(test2), tidy), theme = ttheme("mOrange")) %>%
  tab_add_footnote(text = "two-sample t-test for 2021 & 2021", size = 10, face = "italic")

p1 <- ggarrange(plt1, plt2, ncol = 2)
p2 <- ggarrange(sim_test_statistic1, sim_test_statistic2, ncol = 2)
p3 <- ggarrange(table1, table2, nrow = 2) 
ggarrange(p1, p2, p3, nrow = 3, heights = c(3, 3, 2))
```

So, it is clear from the above two p-values that, Our guess that the Mean AQI of Pollutants have dropped in 2020 compared to 2019 doesn't seem to hold. But we see that the Average AQI of Pollutants for the data we have i.e. January to June of 2021 is definitely higher than that of 2020 by at least 7.5 with 99% confidence, which seems to be consistant with our thinking that the Lockdown might have caused a decrease in AQI Levels in 2020.

Let us try to explore the 2019 and 2020 comparison a bit more closely. We know that the Major Lockdown in India was from March to June of 2020 i.e. the first half of the Year. So, it makes more sense to compare the AQI Levels of 2019 during that phase with 2020 and as an extra check we will see if the values measured in 2021 similar to those of 2019 when the industries and transportation facilities were open as they are in 2021.

```{r average_pollutant_first6month_t_test, fig.asp=0.618, fig.width=12, warning=FALSE, cache=TRUE}
plt3 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020, 2021) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  ggplot(aes(Year, Mean_AQI, fill = Year)) +
  geom_boxplot() +
  stat_summary(fun = "mean") +
  coord_cartesian(ylim = c(20, 100)) +
  labs(x = NULL) +
  theme(legend.position = "None") 

null_distribution1_t <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  hypothesise("independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("2020", "2019"))

obs_diff_means1 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  calculate(stat = "t", order = c("2020", "2019"))

sim_test_statistic1 <- visualise(null_distribution1_t, method = "both") +
  shade_p_value(obs_stat = obs_diff_means1, direction = "left")

test1 <- t.test(filter(air_data_india_Pollutants_Daily, Year == 2020 & Month %in% c(1,2,3,4,5,6))$Mean_AQI, filter(air_data_india_Pollutants_Daily, Year == 2019 & Month %in% c(1,2,3,4,5,6))$Mean_AQI,
                alternative = "less", var.equal = TRUE, conf.level = 0.99)

table1 <- ggtexttable(map_df(list(test1), tidy), theme = ttheme("mOrange")) %>%
  tab_add_footnote(text = "two-sample t-test for 2019 & 2020", size = 10, face = "italic")

null_distribution2_t <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2021, 2019) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  hypothesise("independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("2021", "2019"))

obs_diff_means2 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2021, 2019) & Month %in% c(1,2,3,4,5,6)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  calculate(stat = "t", order = c("2021", "2019"))

sim_test_statistic2 <- visualise(null_distribution2_t, method = "both") +
  shade_p_value(obs_stat = obs_diff_means2, direction = "both")

test2 <- t.test(filter(air_data_india_Pollutants_Daily, Year == 2021 & Month %in% c(1,2,3,4,5,6))$Mean_AQI, filter(air_data_india_Pollutants_Daily, Year == 2019 & Month %in% c(1,2,3,4,5,6))$Mean_AQI,
                alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table2 <- ggtexttable(map_df(list(test2), tidy), theme = ttheme("mOrange")) %>%
  tab_add_footnote(text = "two-sample t-test for 2021 & 2019", size = 10, face = "italic")

p1 <- ggarrange(plt3, ncol = 1)
p2 <- ggarrange(sim_test_statistic1, sim_test_statistic2, ncol = 2)
p3 <- ggarrange(table1, table2, nrow = 2) 
ggarrange(p1, p2, p3, nrow = 3, heights = c(4, 3, 2))
```

Indeed Our guess was right here. The AQI values during the time when there was Lockdown that is the first half of 2020, there was a statistically significant drop in the mean AQI Levels of Pollutants, whereas the mean AQI Level of 2021 and 2019 are same.

A rather surprising fact which we noted in the Visual Overview Section through scatter plot is that the Average AQI Levels during the second half of 2020 was more compared to 2019.

```{r average_pollutant_last6month_t_test, fig.asp=0.618, fig.width=12, warning=FALSE, cache=TRUE}
plt5 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020) & Month %in% c(7,8,9,10, 11, 12)) %>%
  mutate(Year = as.character(Year)) %>%
  ggplot(aes(Year, Mean_AQI, fill = Year)) +
  geom_boxplot() +
  stat_summary(fun = "mean") +
  coord_cartesian(ylim = c(20, 100)) +
  geom_hline(
    yintercept = mean(filter(air_data_india_Pollutants_Daily, Year %in% c(2019, 2020) & Month %in% c(7,8,9,10, 11, 12))$Mean_AQI, na.rm = TRUE), size = 1
  )+
  labs(x = NULL, y = "Mean AQI") +
  theme(legend.position = "None") 

null_distribution1_t <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020) & Month %in% c(7,8,9,10, 11, 12)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  hypothesise("independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "t", order = c("2020", "2019"))

obs_diff_means1 <- air_data_india_Pollutants_Daily %>%
  filter(Year %in% c(2019, 2020) & Month %in% c(7,8,9,10, 11, 12)) %>%
  mutate(Year = as.character(Year)) %>%
  specify(Mean_AQI ~ Year) %>%
  calculate(stat = "t", order = c("2020", "2019"))

sim_test_statistic1 <- visualise(null_distribution1_t, method = "both") +
  shade_p_value(obs_stat = obs_diff_means1, direction = "right")

test1 <- t.test(filter(air_data_india_Pollutants_Daily, Year == 2020 & Month %in% c(7,8,9,10, 11, 12))$Mean_AQI, filter(air_data_india_Pollutants_Daily, Year == 2019 & Month %in% c(7,8,9,10, 11, 12))$Mean_AQI,
                alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table1 <- ggtexttable(map_df(list(test1), tidy), theme = ttheme("mOrange")) %>%
  tab_add_footnote(text = "two-sample t-test for 2019 & 2020", size = 10, face = "italic")

p1 <- ggarrange(plt5, sim_test_statistic1, ncol = 2)
p3 <- ggarrange(table1, nrow = 1) 
ggarrange(p1, p3, nrow = 2, heights = c(6, 1))
```

-   How different are the mean AQI Levels of each individual Pollutant?

Here we will try to look deep into each individual pollutant's mean and will be using similar **two-sample t-tests** and confidence intervals to decide how big a change was observed during the year 2020 compared to 2019 and 2021. For All the Pollutants I suspect that 2020 will be a drop in mean AQI Levels compared to 2019 and 2021 and 2019 & 2021 will have same mean AQI. Let's Test this now

```{r average_indiv_pollutant_first6month_t_test, fig.asp=0.618, fig.width=12, warning=FALSE}
air_data_india_first6month_pollutants_daily <- air_data_india_All_Specie_Daily_1 %>%
  group_by(Year, Month, Day, Specie) %>%
  filter(Year != 2018) %>%
  mutate(Year = as.character(Year)) %>%
  filter(Specie %in% c("co", "no2", "o3", "so2", "pm10", "pm25")) %>%
  filter(Month %in% c(1,2,3,4,5,6)) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

label <- tibble(label = "Row-1: t-test 2020 & 2019\nRow-2: t-test 2021 & 2020\nRow-1: t-test 2019 & 2021")

plt2 <- air_data_india_first6month_pollutants_daily %>%
  filter(Specie %in% c("co", "no2", "o3")) %>%
  ggplot(aes(Year, Mean_AQI, fill = Specie)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  labs(y = NULL, x = NULL) +
  facet_wrap(~Specie, scales = "free") +
  scale_fill_brewer(palette = "Dark2") +
  theme(strip.background = element_blank(),
        strip.text.x = element_blank(), legend.position = c(0.5, 0.025), 
      legend.key = element_rect(fill = "transparent", colour = "transparent")) +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  )

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "co")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "co")$Mean_AQI,
                alternative = "less", var.equal = TRUE, conf.level = 0.99)

test_2 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "co")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "co")$Mean_AQI,
                   alternative = "greater", var.equal = TRUE, conf.level = 0.99)

test_3 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "co")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "co")$Mean_AQI,
                   alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table.fit <- full_join(full_join(select(map_df(list(test_1), tidy), -c(parameter, method, statistic)), select(map_df(list(test_2), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative")), select(map_df(list(test_3), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative"))

table.fit <- table.fit %>%
  select(-c(estimate1, estimate2)) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3)))

table1 <- ggtexttable(table.fit, theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "no2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "no2")$Mean_AQI,
                 alternative = "less", var.equal = TRUE, conf.level = 0.99)

test_2 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "no2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "no2")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

test_3 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "no2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "no2")$Mean_AQI,
                 alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table.fit <- full_join(full_join(select(map_df(list(test_1), tidy), -c(parameter, method, statistic)), select(map_df(list(test_2), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative")), select(map_df(list(test_3), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative"))

table.fit <- table.fit %>%
  select(-c(estimate1, estimate2)) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3)))

table2 <- ggtexttable(table.fit, theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "o3")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "o3")$Mean_AQI,
                 alternative = "less", var.equal = TRUE, conf.level = 0.99)

test_2 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "o3")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "o3")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

test_3 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "o3")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "o3")$Mean_AQI,
                 alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table.fit <- full_join(full_join(select(map_df(list(test_1), tidy), -c(parameter, method, statistic)), select(map_df(list(test_2), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative")), select(map_df(list(test_3), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative"))

table.fit <- table.fit %>%
  select(-c(estimate1, estimate2)) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3)))

table3 <- ggtexttable(table.fit, theme = ttheme("mGreen"), rows = NULL)

table <- ggarrange(table1, table2, table3, ncol = 3)
p1 <- ggarrange(plt2, table, nrow = 2, heights = c(6, 3))

plt3 <- air_data_india_first6month_pollutants_daily %>%
  filter(Specie %in% c("so2", "pm10", "pm25")) %>%
  ggplot(aes(Year, Mean_AQI, fill = Specie)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  labs(y = NULL, x = NULL) +
  facet_wrap(~Specie, scales = "free") +
  scale_fill_brewer(palette = "RdBu") +
  theme(strip.background = element_blank(),
        strip.text.x = element_blank(), legend.position = c(0.5, 0.025),
      legend.key = element_rect(fill = "transparent", colour = "transparent")) +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  )

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "pm10")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "pm10")$Mean_AQI,
                 alternative = "less", var.equal = TRUE, conf.level = 0.99)

test_2 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "pm10")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "pm10")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

test_3 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "pm10")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "pm10")$Mean_AQI,
                 alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table.fit <- full_join(full_join(select(map_df(list(test_1), tidy), -c(parameter, method, statistic)), select(map_df(list(test_2), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative")), select(map_df(list(test_3), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative"))

table.fit <- table.fit %>%
  select(-c(estimate1, estimate2)) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3)))

table1 <- ggtexttable(table.fit, theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "pm25")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "pm25")$Mean_AQI,
                 alternative = "less", var.equal = TRUE, conf.level = 0.99)

test_2 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "pm25")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "pm25")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

test_3 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "pm25")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "pm25")$Mean_AQI,
                 alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table.fit <- full_join(full_join(select(map_df(list(test_1), tidy), -c(parameter, method, statistic)), select(map_df(list(test_2), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative")), select(map_df(list(test_3), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative"))

table.fit <- table.fit %>%
  select(-c(estimate1, estimate2)) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3)))

table2 <- ggtexttable(table.fit, theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "so2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "so2")$Mean_AQI,
                 alternative = "less", var.equal = TRUE, conf.level = 0.99)

test_2 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "so2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "so2")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

test_3 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2021 & Specie == "so2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "so2")$Mean_AQI,
                 alternative = "two.sided", var.equal = TRUE, conf.level = 0.99)

table.fit <- full_join(full_join(select(map_df(list(test_1), tidy), -c(parameter, method, statistic)), select(map_df(list(test_2), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative")), select(map_df(list(test_3), tidy), -c(parameter, method, statistic)), by = c("estimate", "estimate1", "estimate2", "p.value", "conf.low", "conf.high", "alternative"))

table.fit <- table.fit %>%
  select(-c(estimate1, estimate2) )%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3)))

table3 <- ggtexttable(table.fit, theme = ttheme("mGreen"), rows = NULL)

table <- ggarrange(table1, table2, table3, ncol = 3)
p2 <- ggarrange(plt3, table, nrow = 2, heights = c(6, 3))

ggarrange(p1, p2, nrow = 2)
```

**The first row corresponds to t-test between 2019 & 2020, the second row for 2020 & 2021 and third row for 2019 & 2021.**

It is indeed the case that 2020 saw a dip in the mean AQI Levels compared to 2019 & 2021 in most of the pollutants in the first 6 months. It can be clearly seen from the p-values given under respective box plots.

Performing a similar series of tests on the last 6 months of 2020 & 2019. It turns out to be surprising that the mean AQI Levels of most of the pollutants have gone up, even though the first half of the year saw a major dip !

```{r average_indiv_pollutant_lastt6month_t_test, fig.asp=0.618, fig.width=12, warning=FALSE}
air_data_india_first6month_pollutants_daily <- air_data_india_All_Specie_Daily_1 %>%
  group_by(Year, Month, Day, Specie) %>%
  filter(Year != 2018) %>%
  mutate(Year = as.character(Year)) %>%
  filter(Specie %in% c("co", "no2", "o3", "so2", "pm10", "pm25")) %>%
  filter(Month %in% c(7, 8, 9, 10, 11, 12)) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

label <- tibble(label = "Row-1: t-test 2020 & 2019\nRow-2: t-test 2021 & 2020\nRow-1: t-test 2019 & 2021")

plt2 <- air_data_india_first6month_pollutants_daily %>%
  filter(Specie %in% c("co", "no2", "o3")) %>%
  ggplot(aes(Year, Mean_AQI, fill = Specie)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  labs(y = NULL, x = NULL) +
  facet_wrap(~Specie, scales = "free") +
  scale_fill_brewer(palette = "Dark2") +
  theme(strip.background = element_blank(),
        strip.text.x = element_blank(), legend.position = c(0.5, 0.025), 
      legend.key = element_rect(fill = "transparent", colour = "transparent")) +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  )

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "co")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "co")$Mean_AQI,
                alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table1 <- ggtexttable(select(map_df(list(test_1), tidy), -c(parameter, method, statistic, estimate1, estimate2))%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3))), theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "no2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "no2")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table2 <- ggtexttable(select(map_df(list(test_1), tidy), -c(parameter, method, statistic, estimate1, estimate2))%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3))), theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "o3")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "o3")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table3 <- ggtexttable(select(map_df(list(test_1), tidy), -c(parameter, method, statistic, estimate1, estimate2))%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3))), theme = ttheme("mGreen"), rows = NULL)

table <- ggarrange(table1, table2, table3, ncol = 3)
p1 <- ggarrange(plt2, table, nrow = 2, heights = c(6, 3))

plt3 <- air_data_india_first6month_pollutants_daily %>%
  filter(Specie %in% c("so2", "pm10", "pm25")) %>%
  ggplot(aes(Year, Mean_AQI, fill = Specie)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = "mean") +
  labs(y = NULL, x = NULL) +
  facet_wrap(~Specie, scales = "free") +
  scale_fill_brewer(palette = "RdBu") +
  theme(strip.background = element_blank(),
        strip.text.x = element_blank(), legend.position = c(0.5, 0.025),
      legend.key = element_rect(fill = "transparent", colour = "transparent")) +
  guides(
    fill = guide_legend(
      nrow = 1
    )
  )

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "pm10")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "pm10")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table1 <- ggtexttable(select(map_df(list(test_1), tidy), -c(parameter, method, statistic, estimate1, estimate2))%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3))), theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "pm25")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "pm25")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table2 <- ggtexttable(select(map_df(list(test_1), tidy), -c(parameter, method, statistic, estimate1, estimate2))%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3))), theme = ttheme("mGreen"), rows = NULL)

test_1 <- t.test(filter(air_data_india_first6month_pollutants_daily, Year == 2020 & Specie == "so2")$Mean_AQI, filter(air_data_india_first6month_pollutants_daily, Year == 2019 & Specie == "so2")$Mean_AQI,
                 alternative = "greater", var.equal = TRUE, conf.level = 0.99)

table3 <- ggtexttable(select(map_df(list(test_1), tidy), -c(parameter, method, statistic, estimate1, estimate2))%>% 
  mutate(across(where(is.numeric), ~ round(., digits = 3))), theme = ttheme("mGreen"), rows = NULL)

table <- ggarrange(table1, table2, table3, ncol = 3)
p2 <- ggarrange(plt3, table, nrow = 2, heights = c(6, 3))

ggarrange(p1, p2, nrow = 2)
```

We have seen several Tests in this section, and it seems that the first half of 2020 indeed saw a dip in Mean AQI Levels of Pollutants. It is also observed that it was the time when India went under a nation-wide lockdown which might have resulted in the drop of Mean AQI Levels of Pollutants.

But that surprising part which we eventually unfolded is that the Later half of 2020 saw an increase in the AQI Levels of Pollutants where I expected to see a drop or similar AQI Levels.

We will see more of Hypothesis Testing where ever needed, during our Analysis.

### PROBABILITY MODELS

We have already taken a look at the Distributions of all the Pollutants in the Distribution section of the Visual Overview. Now, it's time to fit Probability Models to the data we have observed. It is a really important part of parametric modelling. It will give us an idea about the noise we have in our data and in general what sort of AQI values of different pollutants we can expect every year. We will also carry our analysis on how different is the distribution of Year 2020 compared to 2019 & 2021.

```{r model_fitting_functions}
fit_distribution <- function(data, title_name = "Model & Data", qqtitle = NULL){
  invisible(capture.output(fit_g <<- fitdistrplus::fitdist(data, "gamma")))
  invisible(capture.output(fit_l <<- fitdistrplus::fitdist(data, "lnorm")))
  invisible(capture.output(fit_w <<- fitdistrplus::fitdist(data, "weibull")))
  invisible(capture.output(fit_n <<- fitdistrplus::fitdist(data, "norm")))
  invisible(capture.output(fit_e <<- fitdistrplus::fitdist(data, "exp")))
  
  plot.legend <- c("gamma", "lognormal", "weibull", "normal")#, "exponential")
  
  gof <<- fitdistrplus::gofstat(list(fit_g, fit_l, fit_w, fit_n, fit_e), fitnames = plot.legend)
  
  p1 <- fitdistrplus::denscomp(list(fit_g, fit_l, fit_w, fit_n), legendtext = plot.legend, fitlwd = c(2,2,2,2), xlegend = 0.007, plotstyle = "ggplot") #, fit_e), legendtext = plot.legend, fitlwd = c(3,3.5,4,4.5,1), xlegend = 0.007)
  #fitdistrplus::cdfcomp (list(fit_g, fit_l, fit_w, fit_n, fit_e), legendtext = plot.legend)
  p2 <- fitdistrplus::qqcomp  (list(fit_g, fit_l, fit_w, fit_n), legendtext = plot.legend, plotstyle = "ggplot") # , fit_e), legendtext = plot.legend, xlegend = 0.01, )
  #fitdistrplus::ppcomp  (list(fit_g, fit_l, fit_w, fit_n, fit_e), legendtext = plot.legend)
  
  p1 <- p1 +
    theme(legend.justification = c(1, 1), legend.position = c(1, 1)) + ggtitle(title_name) + theme(axis.title.x = element_blank(), axis.title.y = element_blank())
  
  p2 <- p2  +
    theme(legend.position = "None") + ggtitle(qqtitle) + labs(subtitle = paste(rownames(as.data.frame(gof$ks[which.min(gof$ks)])), "seems to fit the data better.")) + theme(axis.title.x = element_blank(), axis.title.y = element_blank())
  
  
  #print(paste(rownames(as.data.frame(gof$ks[which.min(gof$ks)])), "seems to fit the data well"))
  #distfit.table <- tibble("Distribution" = c("Gamma", "Log-Norm", "Weibull", "Norm", "Expo"), "value" = gof$chisqpvalue) %>%
  #  spread(key = Distribution, value = value) %>%
  #  mutate(across(where(is.numeric), ~ round(., digits = 3)))
  #return(distfit.table)
  p <- ggarrange(p1, p2, ncol = 2)
  return(p)
}

# Calculates the sqrt(f).sqrt(g) things that needs to be maximized for minimum hellinger distance
hellinger_distance.minimizer <- function(...) {
  y <<- as.list(...) 
  x <<- as.list(c(NA, unlist(y)))
  x[[1]] <<- c(-Inf, gof$chisqbreaks, Inf)
  hellinger <<- sum(sqrt(diff(do.call(distribution, x)))*sqrt(as.data.frame(gof$chisqtable)[1:(length(gof$chisqbreaks)+1), 3] / sum(as.data.frame(gof$chisqtable)[1:(length(gof$chisqbreaks)+1), 3])))
  return(hellinger)
}

# Fits Model based on Minimizing Hellinger Distance
hellinger_fit <- function(data, distribution){
  data1 <<- data
  distribution <<- distribution
  fit <<- fitdistrplus::fitdist(data, sub('.', '', distribution))
  gof <<- fitdistrplus::gofstat(fit, fitnames = c(sub('.', '', distribution))) 
  estimates <<- optim(par = as.vector(fit$estimate), fn = hellinger_distance.minimizer, control = list(fnscale=-1))
  sq_hellinger_dist <<- sum(diff(do.call(distribution, x))) + sum(as.data.frame(gof$chisqtable)[1:(length(gof$chisqbreaks)+1), 3] / sum(as.data.frame(gof$chisqtable)[1:(length(gof$chisqbreaks)+1), 3])) - 2*hellinger_distance.minimizer(estimates$par)
  return(list("Hellinger_Estimates" = estimates$par, "Square_Hellinger_Distance" = sq_hellinger_dist))
}

# Comparing Hellinger Fit with MLE Fit
compare_hellinger_fit_v_MLE <- function(data, distribution){
  fit_MLE <<- fitdistrplus::fitdist(data, sub('.', '', distribution))
  fit_hellinger <<- fitdistrplus::fitdist(data, sub('.', '', distribution))
  fit_hellinger$estimate <<- hellinger_fit(data, distribution)$Hellinger_Estimates
  
  plot.legend <- c("MLE_Fit", "Hellinger_Fit")
  p1 <- fitdistrplus::denscomp(list(fit_MLE, fit_hellinger), legendtext = plot.legend, fitlwd = c(2, 2), xlegend = 0.007, plotstyle = "ggplot")
  p2 <- fitdistrplus::qqcomp  (list(fit_MLE, fit_hellinger), legendtext = plot.legend, plotstyle = "ggplot")
  p1 <- p1 + theme(legend.justification = c(1, 1), legend.position = c(1, 1)) + ggtitle("Hellinger Fit vs MLE Fit Model")
  p2 <- p2 + theme(legend.position = "None")
  ggarrange(p1, p2, ncol = 2)
}
```

```{r expectation_variance_finders}
ev_finder <- function(transform = identity) {
  function(f, ..., from = -Inf, to = Inf) {
    integrate(function(x) transform(x) * f(x, ...), from, to)
  }
}

moment_finder <- function(n, c = 0) {
  ev_finder(function(x) (x - c) ^ n)
}

find_mean <- moment_finder(1)
find_variance <- function(f, ...) {
  mu <- find_mean(f, ...)$value
  moment_finder(2, mu)(f, ...)
}

```

-   One Important thing to keep in mind is that we have 3 types of Measure of AQI Levels for Each Day that is Maximum AQI detected on that day, Minimum AQI Detected on that Day and Median AQI Detected. So merging all these data results in bad fit for any model since there are lots of data points for high value and median value resulting in two different distributions. So we will take a look at them separately. And the Combined AQI for all pollutants which we will see will be without including particulate matter because they too take much higher value compared to the other pollutants.

-   We mostly observe that the histograms look quite close to Gamma, Lognormal, Weibull and Normal Density. So we tried fitting from these four models and if needed we will explore other models too. We will also take a look at how well the model fits our data best using **Chi-square Goodness of Fit Test**. In case of outliers we shift to some distance based model fitting approach i.e. **Hellinger-Distance**

-   Let's Start by comparing the Models for Maximum AQI Level of 2019, 2020 & 2021.

```{r Model_Max_AQI, fig.asp=0.8, fig.width=12, warning=FALSE, message=FALSE, results='hide'}
air_data_india_Pollutants_nonpollutants_daily <- air_data_india_All_Specie_Daily_1 %>%
  filter(Year != 2018) %>% # There is a lot of Missing values in this year
  spread(key = Specie, value = AQI) %>%
  select(-precipitation) %>%
  gather(dew, humidity, pressure, temperature, `wind-gust`, `wind-speed`, key = "non_pollutants", value = Levels) %>%
  gather(co, so2, no2, o3, pm10, pm25, key = "pollutants", value = "AQI")

air_data_pollutants_2019_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2019 & Measure == "Avg_Max") %>% #  -----------------------------------------------LOOOOK!!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2019_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

# Normal Data fits well
invisible(capture.output(p1 <- fit_distribution(air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2019", "QQ-Plot")))

t1 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# -------------2020 ------------------------
air_data_pollutants_2020_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2020 & Measure == "Avg_Max") %>% #   ----------------------------------------LOOOOOOOOOOKKKKKKKK!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2020_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p2 <- fit_distribution(air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2020")))

t2 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# ------------2021-------------
# First 6 months Only
air_data_pollutants_2021_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2021 & Measure == "Avg_Max" & Month %in% c(1,2,3,4,5,6)) %>% # ------------------------------LOOOOOOOOOOOOOOOOOOK!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2021_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2021_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2021_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2021_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2021_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2021_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p3 <- fit_distribution(air_data_pollutants_2021_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2021")))

t3 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))

table1 <- ggtexttable(tibble(Fit = c(colnames(t1)[1], as.character(t1[1]),colnames(t1)[2], as.character(t1[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table2 <- ggtexttable(tibble(Fit = c(colnames(t2)[1], as.character(t2[1]),colnames(t2)[2], as.character(t2[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table3 <- ggtexttable(tibble(Fit = c(colnames(t3)[1], as.character(t3[1]),colnames(t3)[2], as.character(t3[2])[1])), theme = ttheme("mCyan"), rows = NULL)

table1a <-  ggtexttable(tibble(Moments = c("Mean", round(find_mean(dweibull, scale = as.numeric(t1[1]), shape = as.numeric(t1[2]))$value, digits = 2), "Var", round(find_variance(dweibull, scale = as.numeric(t1[1]), shape = as.numeric(t1[2]))$value, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table2a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t2[1]) + 0.5*as.numeric(t2[2])^2), digits = 2), "Var", round(exp(as.numeric(t2[1])*2 + 0.5*4*as.numeric(t2[2])^2) - (exp(as.numeric(t2[1])*1 + 0.5*as.numeric(t2[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table3a <-  ggtexttable(tibble(Moments = c("Mean", round(find_mean(dweibull, scale = as.numeric(t3[1]), shape = as.numeric(t3[2]))$value, digits = 2), "Var", round(find_variance(dweibull, scale = as.numeric(t3[1]), shape = as.numeric(t3[2]))$value, digits = 2))), theme = ttheme("mGreen"), rows = NULL)

table1 <- ggarrange(table1, table1a, nrow = 2)
table2 <- ggarrange(table2, table2a, nrow = 2)
table3 <- ggarrange(table3, table3a, nrow = 2)

ggarrange(p1, table1, p2, table2, p3, table3, nrow = 3, ncol = 2, widths = c(10,1))
```

The Above fitted model quite surprisingly shows an increase in the expected Maximum AQI Level in 2020, as well as 2021 where we could have thought that the lockdowns during 2020 might have decreased All the Levels of AQI. But wait! It can be because we also saw previously that the second half of 2020 saw an increase in AQI Levels where the AQI Levels exceeded that of 2019. So, let's take a look at the first 6 months only for all the 3 Years.

```{r Model_Max_AQI_First6Month, fig.asp=0.8, fig.width=12, warning=FALSE, message=FALSE, results='hide'}
air_data_pollutants_2019_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2019 & Measure == "Avg_Max" & Month %in% c(1,2,3,4,5,6)) %>% #  -----------------------------------------------LOOOOK!!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2019_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

# Normal Data fits well
invisible(capture.output(p1 <- fit_distribution(air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2019")))

t1 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# -------------2020 ------------------------
air_data_pollutants_2020_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2020 & Measure == "Avg_Max" & Month %in% c(1,2,3,4,5,6)) %>% #   ----------------------------------------LOOOOOOOOOOKKKKKKKK!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2020_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p2 <- fit_distribution(air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2020")))

t2 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# ------------2021-------------
# First 6 months Only
air_data_pollutants_2021_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2021 & Measure == "Avg_Max" & Month %in% c(1,2,3,4,5,6)) %>% # ------------------------------LOOOOOOOOOOOOOOOOOOK!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2021_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2021_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2021_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2021_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2021_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2021_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p3 <- fit_distribution(air_data_pollutants_2021_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2021")))

t3 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))

table1 <- ggtexttable(tibble(Fit = c(colnames(t1)[1], as.character(t1[1]),colnames(t1)[2], as.character(t1[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table2 <- ggtexttable(tibble(Fit = c(colnames(t2)[1], as.character(t2[1]),colnames(t2)[2], as.character(t2[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table3 <- ggtexttable(tibble(Fit = c(colnames(t3)[1], as.character(t3[1]),colnames(t3)[2], as.character(t3[2])[1])), theme = ttheme("mCyan"), rows = NULL)

table1a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t1[1]) + 0.5*as.numeric(t1[2])^2), digits = 2), "Var", round(exp(as.numeric(t1[1])*2 + 0.5*4*as.numeric(t1[2])^2) - (exp(as.numeric(t1[1])*1 + 0.5*as.numeric(t1[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table2a <-  ggtexttable(tibble(Moments = c("Mean", round(find_mean(dgamma, rate = as.numeric(t2[1]), shape = as.numeric(t2[2]))$value, digits = 2), "Var", round(find_variance(dgamma, rate = as.numeric(t2[1]), shape = as.numeric(t2[2]))$value, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table3a <-  ggtexttable(tibble(Moments = c("Mean", round(find_mean(dweibull, scale = as.numeric(t3[1]), shape = as.numeric(t3[2]))$value, digits = 2), "Var", round(find_variance(dweibull, scale = as.numeric(t3[1]), shape = as.numeric(t3[2]))$value, digits = 2))), theme = ttheme("mGreen"), rows = NULL)

table1 <- ggarrange(table1, table1a, nrow = 2)
table2 <- ggarrange(table2, table2a, nrow = 2)
table3 <- ggarrange(table3, table3a, nrow = 2)

ggarrange(p1, table1, p2, table2, p3, table3, nrow = 3, ncol = 2, widths = c(10,1))
```

But No! It seems indeed the Maximum AQI Levels were high even though there was a Lockdown during this phase, which seems pretty strange!

Taking a look at the later half of 2020 & 2019, we see

```{r Model_Max_AQI_Last6Month, fig.asp=0.618, fig.width=12, warning=FALSE, message=FALSE, results='hide'}
air_data_pollutants_2019_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2019 & Measure == "Avg_Max" & !(Month %in% c(1,2,3,4,5,6))) %>% #  -----------------------------------------------LOOOOK!!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2019_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

# Normal Data fits well
invisible(capture.output(p1 <- fit_distribution(air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2019")))

t1 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# -------------2020 ------------------------
air_data_pollutants_2020_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2020 & Measure == "Avg_Max" & !(Month %in% c(1,2,3,4,5,6))) %>% #   ----------------------------------------LOOOOOOOOOOKKKKKKKK!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2020_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p2 <- fit_distribution(air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Maximum AQI 2020")))

t2 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))


table1 <- ggtexttable(tibble(Fit = c(colnames(t1)[1], as.character(t1[1]),colnames(t1)[2], as.character(t1[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table2 <- ggtexttable(tibble(Fit = c(colnames(t2)[1], as.character(t2[1]),colnames(t2)[2], as.character(t2[2])[1])), theme = ttheme("mCyan"), rows = NULL)


table1a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t1[1]) + 0.5*as.numeric(t1[2])^2), digits = 2), "Var", round(exp(as.numeric(t1[1])*2 + 0.5*4*as.numeric(t1[2])^2) - (exp(as.numeric(t1[1])*1 + 0.5*as.numeric(t1[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table2a <-  ggtexttable(tibble(Moments = c("Mean", round(find_mean(dgamma, rate = as.numeric(t2[1]), shape = as.numeric(t2[2]))$value, digits = 2), "Var", round(find_variance(dgamma, rate = as.numeric(t2[1]), shape = as.numeric(t2[2]))$value, digits = 2))), theme = ttheme("mGreen"), rows = NULL)


table1 <- ggarrange(table1, table1a, nrow = 2)
table2 <- ggarrange(table2, table2a, nrow = 2)

ggarrange(p1, table1, p2, table2, nrow = 2, ncol = 2, widths = c(10,1))
```

That the first Model doesn't seem to fit the data well mostly because of scattered values and our model fails to track the portion well where there is maximum number of observations. We can improve on this by fitting using Minimization of Hellinger-Distance, but still practically it doesn't make much of a difference as the expectation remains almost the same.

```{r compare_hellinger, fig.asp=0.618, fig.width=12, warning=FALSE, message=FALSE, results='hide'}
invisible(capture.output(p1 <- compare_hellinger_fit_v_MLE(air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "plnorm")))

t1 <- tibble("MLE_Fit" = c("meanlog", round(fit_MLE$estimate[1], digits = 2), "sdlog", round(fit_MLE$estimate[2], digits = 2)))

t2 <- tibble("Hel_Fit" = c("meanlog", round(fit_hellinger$estimate[1], digits = 2), "sdlog", round(fit_hellinger$estimate[2], digits = 2)))
  
table1 <- ggtexttable(tibble(MLE_Fit = c(t1[1,1]$MLE_Fit, t1[2,1]$MLE_Fit, t1[3,1]$MLE_Fit, t1[4,1]$MLE_Fit)), theme = ttheme("mCyan"), rows = NULL)
table2 <- ggtexttable(tibble(Hel_Fit = c(t2[1,1]$Hel_Fit, t2[2,1]$Hel_Fit, t2[3,1]$Hel_Fit, t2[4,1]$Hel_Fit)), theme = ttheme("mCyan"), rows = NULL)


table1a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t1[2,1]) + 0.5*as.numeric(t1[4,1])^2), digits = 2), "Var", round(exp(as.numeric(t1[2,1])*2 + 0.5*4*as.numeric(t1[4,1])^2) - (exp(as.numeric(t1[2,1])*1 + 0.5*as.numeric(t1[4,1])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table2a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t2[2,1]) + 0.5*as.numeric(t2[4,1])^2), digits = 2), "Var", round(exp(as.numeric(t2[2,1])*2 + 0.5*4*as.numeric(t2[4,1])^2) - (exp(as.numeric(t2[2,1])*1 + 0.5*as.numeric(t2[4,1])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)


table1 <- ggarrange(table1, table1a, nrow = 2)
table2 <- ggarrange(table2, table2a, nrow = 2)

table <- ggarrange(table1, table2, nrow = 2)
ggarrange(p1, table, nrow = 1, ncol = 2, widths = c(10,1))
```

Looking at the QQ-Plot the Hellinger Fit seems better.

-   Now, we shall take a look at the Median AQI Levels of Pollutants for the first 6 months of the Year.

```{r Model_Median_AQI_Indiv, fig.asp=0.8, fig.width=12, warning=FALSE, message=FALSE, results='hide'}
air_data_pollutants_2019_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2019 & Measure == "Avg_Median" & Month %in% c(1,2,3,4,5,6)) %>% #  -----------------------------------------------LOOOOK!!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2019_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

# Normal Data fits well
invisible(capture.output(p1 <- fit_distribution(air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Median AQI 2019")))

t1 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# -------------2020 ------------------------
air_data_pollutants_2020_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2020 & Measure == "Avg_Median" & Month %in% c(1,2,3,4,5,6)) %>% #   ----------------------------------------LOOOOOOOOOOKKKKKKKK!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2020_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p2 <- fit_distribution(air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Median AQI 2020")))

t2 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# ------------2021-------------
# First 6 months Only
air_data_pollutants_2021_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2021 & Measure == "Avg_Median" & Month %in% c(1,2,3,4,5,6)) %>% # ------------------------------LOOOOOOOOOOOOOOOOOOK!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2021_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2021_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2021_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2021_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2021_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2021_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p3 <- fit_distribution(air_data_pollutants_2021_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Median AQI 2021")))

t3 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))

table1 <- ggtexttable(tibble(Fit = c(colnames(t1)[1], as.character(t1[1]),colnames(t1)[2], as.character(t1[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table2 <- ggtexttable(tibble(Fit = c(colnames(t2)[1], as.character(t2[1]),colnames(t2)[2], as.character(t2[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table3 <- ggtexttable(tibble(Fit = c(colnames(t3)[1], as.character(t3[1]),colnames(t3)[2], as.character(t3[2])[1])), theme = ttheme("mCyan"), rows = NULL)

table1a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t1[1]) + 0.5*as.numeric(t1[2])^2), digits = 2), "Var", round(exp(as.numeric(t1[1])*2 + 0.5*4*as.numeric(t1[2])^2) - (exp(as.numeric(t1[1])*1 + 0.5*as.numeric(t1[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table2a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t2[1]) + 0.5*as.numeric(t2[2])^2), digits = 2), "Var", round(exp(as.numeric(t2[1])*2 + 0.5*4*as.numeric(t2[2])^2) - (exp(as.numeric(t2[1])*1 + 0.5*as.numeric(t2[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table3a <-  ggtexttable(tibble(Moments = c("Mean", round(find_mean(dweibull, scale = as.numeric(t3[1]), shape = as.numeric(t3[2]))$value, digits = 2), "Var", round(find_variance(dweibull, scale = as.numeric(t3[1]), shape = as.numeric(t3[2]))$value, digits = 2))), theme = ttheme("mGreen"), rows = NULL)

table1 <- ggarrange(table1, table1a, nrow = 2)
table2 <- ggarrange(table2, table2a, nrow = 2)
table3 <- ggarrange(table3, table3a, nrow = 2)

ggarrange(p1, table1, p2, table2, p3, table3, nrow = 3, ncol = 2, widths = c(10,1))
```

-   Later Half of 2020 & 2021 Compared.

```{r Model_Median_AQI_Last6Month, fig.asp=0.618, fig.width=12, warning=FALSE, message=FALSE, results='hide'}
air_data_pollutants_2019_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2019 & Measure == "Avg_Median" & !(Month %in% c(1,2,3,4,5,6))) %>% #  -----------------------------------------------LOOOOK!!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2019_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2019_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2019_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

# Normal Data fits well
invisible(capture.output(p1 <- fit_distribution(air_data_pollutants_2019_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Median AQI 2019")))

t1 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))
# -------------2020 ------------------------
air_data_pollutants_2020_avg_median <- air_data_india_Pollutants_nonpollutants_daily %>%
  filter(Year == 2020 & Measure == "Avg_Median" & !(Month %in% c(1,2,3,4,5,6))) %>% #   ----------------------------------------LOOOOOOOOOOKKKKKKKK!!!!!!!!!
  select(-c("non_pollutants", "Levels"))

air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm <- air_data_pollutants_2020_avg_median %>%
  filter(!(pollutants %in% c("pm10", "pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm10 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm10"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

air_data_pollutants_2020_avg_median_all_pol_summarized_pm25 <- air_data_pollutants_2020_avg_median %>%
  filter((pollutants %in% c("pm25"))) %>%
  ungroup() %>%
  group_by(Year, Month, Day) %>%
  summarise(Mean_AQI = mean(AQI, na.rm = TRUE))

invisible(capture.output(p2 <- fit_distribution(air_data_pollutants_2020_avg_median_all_pol_summarized_wo_pm$Mean_AQI, "Median AQI 2020")))

t2 <- (map_df(list(list(fit_g, fit_l, fit_w, fit_n, fit_e)[as.numeric(which.min(gof$ks))][[1]]$estimate), tidy)) %>%
    spread(key = names, value = x) %>% 
  mutate(across(where(is.numeric), ~ round(., digits = 2)))


table1 <- ggtexttable(tibble(Fit = c(colnames(t1)[1], as.character(t1[1]),colnames(t1)[2], as.character(t1[2])[1])), theme = ttheme("mCyan"), rows = NULL)
table2 <- ggtexttable(tibble(Fit = c(colnames(t2)[1], as.character(t2[1]),colnames(t2)[2], as.character(t2[2])[1])), theme = ttheme("mCyan"), rows = NULL)


table1a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t1[1]) + 0.5*as.numeric(t1[2])^2), digits = 2), "Var", round(exp(as.numeric(t1[1])*2 + 0.5*4*as.numeric(t1[2])^2) - (exp(as.numeric(t1[1])*1 + 0.5*as.numeric(t1[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)
table2a <-  ggtexttable(tibble(Moments = c("Mean", round(exp(as.numeric(t2[1]) + 0.5*as.numeric(t2[2])^2), digits = 2), "Var", round(exp(as.numeric(t2[1])*2 + 0.5*4*as.numeric(t2[2])^2) - (exp(as.numeric(t2[1])*1 + 0.5*as.numeric(t2[2])^2))^2, digits = 2))), theme = ttheme("mGreen"), rows = NULL)


table1 <- ggarrange(table1, table1a, nrow = 2)
table2 <- ggarrange(table2, table2a, nrow = 2)

ggarrange(p1, table1, p2, table2, nrow = 2, ncol = 2, widths = c(10,1))
```
